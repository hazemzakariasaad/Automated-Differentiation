{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class comp_node :\n",
    "    def __init__(self ,val ,children=[],op=\"assign\"):\n",
    "        self.val= val \n",
    "        self.children= children  \n",
    "        self.grad=0\n",
    "        self.op= op\n",
    "        self.backward = lambda : None     \n",
    "    def __sub__(self ,other):\n",
    "        if not isinstance(other,comp_node):\n",
    "            other = comp_node (val = other)\n",
    "        out = comp_node(val = self.val - other.val, \n",
    "                        children= [self,other],op=\"sub\")\n",
    "        def backward():\n",
    "            self.grad += out.grad * (-1)\n",
    "            other.grad += out.grad * (-1)\n",
    "        out.backward= backward \n",
    "        return out \n",
    "    def __rsub__(self ,other):\n",
    "        if not isinstance(other,comp_node):\n",
    "            other = comp_node (val = other)\n",
    "        # out = comp_node(val =  other.val - self.val , \n",
    "        #                 children= [self,other],op=\"sub\")\n",
    "        return other - self  \n",
    "    def __add__(self ,other):\n",
    "        if not isinstance(other,comp_node):\n",
    "            other = comp_node (val = other)\n",
    "        out = comp_node(val = self.val + other.val, \n",
    "                        children= [self,other],op=\"add\")\n",
    "        def backward(): \n",
    "            self.grad += out.grad * (1)\n",
    "            other.grad += out.grad * (1)\n",
    "        out.backward=backward    \n",
    "        return out \n",
    "    def __radd__(self ,other):\n",
    "        if not isinstance(other,comp_node):\n",
    "            other = comp_node (val = other)\n",
    "        out = comp_node(val = self.val + other.val, \n",
    "                        children= [self,other],op=\"add\")\n",
    "        return out\n",
    "    def __mul__(self ,other):\n",
    "        if not isinstance(other,comp_node):\n",
    "            other = comp_node (val = other)\n",
    "        out= comp_node(val = self.val * other.val ,\n",
    "                       children =[self],op = \"multi\")\n",
    "        def backword(): \n",
    "            self.grad += out.grad * other.val\n",
    "            other.grad += out.grad * self.val\n",
    "        out.backward = backword  \n",
    "        return out  \n",
    "    def __rmul__(self ,other):\n",
    "        if not isinstance(other,comp_node):\n",
    "            other = comp_node (val = other)\n",
    "        out= comp_node(val = self.val * other.val ,\n",
    "                       children =[self],op = \"multi\")\n",
    "        return out \n",
    "    def __pow__ (self,exp):\n",
    "        if not isinstance(exp,(int,float)):\n",
    "             raise ValueError (\"unsupported type\")\n",
    "        out = comp_node(val = self.val **exp ,\n",
    "                        children = [self],op=\"power\")\n",
    "        def backward():\n",
    "            self.grad += out.grad * (exp * self.val**(exp-1))\n",
    "        out.backward = backward\n",
    "        return out  \n",
    "    def __eq__ (self ,other):\n",
    "        return self.val == other.val\n",
    "    def __repr__(self):\n",
    "        return f\"op:{self.op} | val: {self.val} | children: {len(self.children)}| grad:{self.grad}\" \n",
    "    def __truediv__(self, other):\n",
    "        other = self.__to_comp_node(other)\n",
    "        if other.val == 0:\n",
    "          raise ValueError(\"can not divide by zero\")\n",
    "        out = comp_node(val=self.val / other.val, children=[self, other], op=\"div\")\n",
    "        def __backward_prop():\n",
    "            # d(u/v)/dx = (v*du/dx - u*dv/dx) / v^2 ---> For the first operand 'self'\n",
    "            self.grad += out.grad / other.val\n",
    "            # d(u/v)/dv = -u/(v^2) ----> For the second operand 'other'\n",
    "            other.grad -= out.grad * self.val / (other.val**2)\n",
    "            out.backward_prop = __backward_prop\n",
    "            return out\n",
    "        \n",
    "    def sin(self):\n",
    "            out = comp_node(val=np.sin(self.val), children=[self], op=\"sin\")\n",
    "            def __backward_prop():\n",
    "                self.grad += out.grad * np.cos(self.val)\n",
    "            out.backward_prop = __backward_prop\n",
    "            return out\n",
    "        \n",
    "    def cos(self):\n",
    "            out = comp_node(val=np.cos(self.val), children=[self], op=\"cos\")\n",
    "            def __backward_prop():\n",
    "                self.grad -= out.grad * np.sin(self.val)\n",
    "            out.backward_prop = __backward_prop\n",
    "            return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op:power | val: 0.5472122517293468 | children: 1| grad:1\n",
      "0 op:power | val: 0.5472122517293468 | children: 1| grad:1\n",
      "1 op:add | val: 0.29944124844270203 | children: 2| grad:0.9137222319490423\n",
      "2 op:power | val: 0.10426550456264216 | children: 1| grad:0.9137222319490423\n",
      "3 op:power | val: 0.19517574388005984 | children: 1| grad:0.9137222319490423\n",
      "4 op:sub | val: -0.32290169488970194 | children: 2| grad:-0.5900849147094943\n",
      "5 op:sub | val: -0.4417869892607294 | children: 2| grad:-0.8073411877467226\n",
      "6 op:assign | val: 0.3 | children: 0| grad:0.5900849147094943\n",
      "7 op:assign | val: 0.3 | children: 0| grad:0.8073411877467226\n",
      "op:power | val: 0.10426550456264216 | children: 1| grad:0.9137222319490423\n"
     ]
    }
   ],
   "source": [
    "from random import Random\n",
    "rand = Random(5)\n",
    "def generate_point (N=1000):\n",
    "    return ([rand.uniform(0, 1) for xi in range(N)],\n",
    "            [rand.uniform(0, 1) for yi in range(N) ])\n",
    "datax ,datay = generate_point(1)\n",
    "xp , yp = comp_node(val=0.3 ),comp_node(val=0.3)\n",
    "def loss_graph (xp,yp, datax,datay):\n",
    "    Ix ,Iy = xp- datax , yp- datay\n",
    "    gx ,gy = Ix**2, Iy**2\n",
    "    M = gx + gy \n",
    "    l= M ** 0.5 \n",
    "    return l , [l,M,gx,gy,Ix,Iy,xp,yp]\n",
    "l ,rev_topo_order = loss_graph(xp,yp,datax[0],datay[0])\n",
    "rev_topo_order[0].grad = 1\n",
    "print(l) ## 7agat kteer mt8zna gwa 34an kda 3mlt repr \n",
    "for i ,node in enumerate(rev_topo_order):\n",
    "    node.backward()\n",
    "    print(i,node) \n",
    "print(rev_topo_order[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (6 - comp_node(5)).val == -1 \n",
    "# assert (comp_node(6)**2).val == 36"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
